# Pipeline de Dados

É importante saber que a **pipeline de dados é uma série de etapas de processamento para preparar dados de uma organização para análise**.

As organizações possuem um grande volume de dados de várias fontes, como aplicativos, dispositivos de Internet das Coisas (IoT) e outros canais digitais. No entanto, os dados brutos são inúteis; eles devem ser movidos, classificados, filtrados, reformatados e analisados para business intelligence. Um pipeline de dados inclui várias tecnologias para verificar, resumir e encontrar padrões nos dados para informar as decisões de negócios. Pipelines de dados bem organizados oferecem suporte a vários projetos de big data, como visualizações de dados, análises exploratórias de dados e tarefas de machine learning.

## Tipos de Processamento

### Processamento Streaming

O **streaming de dados** é o processo de transmissão de um fluxo contínuo de dados (também conhecido como stream) que normalmente é enviado a um software de processamento de fluxo para gerar informações valiosas.
